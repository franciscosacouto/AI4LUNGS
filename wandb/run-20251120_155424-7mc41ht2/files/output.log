GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
C:\Users\franc\miniconda3\envs\nlst_fm\Lib\site-packages\pytorch_lightning\trainer\connectors\logger_connector\logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default
  warning_cache.warn(

  | Name  | Type       | Params
-------------------------------------
0 | model | Sequential | 37.0 K
-------------------------------------
37.0 K    Trainable params
0         Non-trainable params
37.0 K    Total params
0.148     Total estimated model params size (MB)
Epoch 199: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 62.39it/s, v_num=22, val_loss=4.000]
C:\Users\franc\miniconda3\envs\nlst_fm\Lib\site-packages\pytorch_lightning\trainer\connectors\data_connector.py:442: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
C:\Users\franc\miniconda3\envs\nlst_fm\Lib\site-packages\torchsurv\loss\cox.py:222: UserWarning: Ties in event time detected; using efron's method to handle ties.
  warnings.warn(
C:\Users\franc\miniconda3\envs\nlst_fm\Lib\site-packages\pytorch_lightning\trainer\connectors\data_connector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
C:\Users\franc\miniconda3\envs\nlst_fm\Lib\site-packages\pytorch_lightning\loops\fit_loop.py:281: PossibleUserWarning: The number of training batches (8) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
  rank_zero_warn(
Testing DataLoader 0: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 364.47it/s]
`Trainer.fit` stopped: `max_epochs=200` reached.
C:\Users\franc\miniconda3\envs\nlst_fm\Lib\site-packages\pytorch_lightning\trainer\connectors\data_connector.py:442: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Test C-index = 0.5622  (95% CI: 0.2886, 0.8359)

Time-dependent AUC(t):
Times: tensor([  90.,  348.,  394.,  491.,  553.,  645.,  649.,  664.,  703.,  819.,
         950.,  964., 1074., 1099., 1101., 1239., 1355., 1732., 1779., 1794.,
        2012., 2064., 2140., 2202., 2216., 2227., 2242., 2252., 2253., 2255.,
        2255., 2260., 2261., 2309., 2318., 2326., 2326., 2338., 2349., 2362.,
        2392., 2394., 2400., 2401., 2405., 2406., 2407., 2429., 2439., 2445.,
        2451., 2452., 2455., 2461., 2474., 2483., 2484., 2489., 2499., 2504.,
        2520., 2531., 2543., 2556., 2561., 2599., 2601., 2607., 2624., 2625.,
        2631., 2632., 2634., 2644., 2648., 2667., 2732., 2760., 2765., 2783.])
AUC: tensor([0.6203, 0.7372, 0.8052, 0.8487, 0.7467, 0.6734, 0.6942, 0.6286, 0.5974,
        0.6426, 0.5902, 0.6035, 0.5953, 0.5513, 0.5376, 0.5161, 0.5391, 0.5639])
Testing DataLoader 0: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 10.60it/s]
─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
Runningstage.testing metric      DataLoader 0
─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
      test_auc_mean         0.6384010910987854
       test_cindex          0.5622490048408508
─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
